Command Line Args: Namespace(config_file='configs/fsod/finetune_R_50_C4_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=['MODEL.WEIGHTS', './output/fsod/finetune_dir/R_50_C4_1x/model_final.pth'], resume=False)
[32m[10/15 23:59:18 detectron2]: [0mRank of current process: 0. World size: 2
[32m[10/15 23:59:18 detectron2]: [0mEnvironment info:
----------------------  ------------------------------------------------------------------------------
sys.platform            linux
Python                  3.8.3 (default, Jul  2 2020, 16:21:59) [GCC 7.3.0]
numpy                   1.18.5
detectron2              0.2.1 @/home/liuwj/.local/lib/python3.8/site-packages/detectron2
Compiler                GCC 7.3
CUDA compiler           CUDA 10.1
detectron2 arch flags   sm_35, sm_37, sm_50, sm_52, sm_60, sm_61, sm_70, sm_75
DETECTRON2_ENV_MODULE   <not set>
PyTorch                 1.5.1 @/home/liuwj/anaconda3/lib/python3.8/site-packages/torch
PyTorch debug build     False
GPU available           True
GPU 0,1                 GeForce RTX 2080 Ti
CUDA_HOME               /usr/local/cuda-10.1
Pillow                  7.2.0
torchvision             0.6.0a0+35d732a @/home/liuwj/anaconda3/lib/python3.8/site-packages/torchvision
torchvision arch flags  sm_35, sm_50, sm_60, sm_70, sm_75
fvcore                  0.1.2.post20201013
cv2                     4.4.0
----------------------  ------------------------------------------------------------------------------
PyTorch built with:
  - GCC 7.3
  - C++ Version: 201402
  - Intel(R) Math Kernel Library Version 2020.0.1 Product Build 20200208 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v0.21.1 (Git Hash 7d2fd500bc78936d1d648ca713b901012f470dbc)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 10.1
  - NVCC architecture flags: -gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_61,code=sm_61;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_37,code=compute_37
  - CuDNN 7.6.3
  - Magma 2.5.2
  - Build settings: BLAS=MKL, BUILD_TYPE=Release, CXX_FLAGS= -Wno-deprecated -fvisibility-inlines-hidden -fopenmp -DNDEBUG -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DUSE_INTERNAL_THREADPOOL_IMPL -O2 -fPIC -Wno-narrowing -Wall -Wextra -Werror=return-type -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-sign-compare -Wno-unused-parameter -Wno-unused-variable -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-error=deprecated-declarations -Wno-stringop-overflow -Wno-error=pedantic -Wno-error=redundant-decls -Wno-error=old-style-cast -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Wno-stringop-overflow, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, USE_CUDA=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=ON, USE_NNPACK=ON, USE_OPENMP=ON, USE_STATIC_DISPATCH=OFF, 

[32m[10/15 23:59:18 detectron2]: [0mCommand line arguments: Namespace(config_file='configs/fsod/finetune_R_50_C4_1x.yaml', dist_url='tcp://127.0.0.1:50152', eval_only=True, machine_rank=0, num_gpus=2, num_machines=1, opts=['MODEL.WEIGHTS', './output/fsod/finetune_dir/R_50_C4_1x/model_final.pth'], resume=False)
[32m[10/15 23:59:18 detectron2]: [0mContents of args.config_file=configs/fsod/finetune_R_50_C4_1x.yaml:
_BASE_: "Base-FSOD-C4.yaml"
MODEL:
  WEIGHTS: "./output/fsod/R_50_C4_1x/model_final.pth" 
  MASK_ON: False
  RESNETS:
    DEPTH: 50
  BACKBONE:
    FREEZE_AT: 5
DATASETS:
  TRAIN: ("coco_2017_train_voc_10_shot",)
  TEST: ("coco_2017_val",)
SOLVER:
  IMS_PER_BATCH: 4
  BASE_LR: 0.001
  STEPS: (2000, 3000)
  MAX_ITER: 3000
  WARMUP_ITERS: 200
INPUT:
  FS:
    FEW_SHOT: True
    SUPPORT_WAY: 2
    SUPPORT_SHOT: 9
  MIN_SIZE_TRAIN: (440, 472, 504, 536, 568, 600)
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MAX_SIZE_TEST: 1000
OUTPUT_DIR: './output/fsod/finetune_dir/R_50_C4_1x'


[32m[10/15 23:59:18 detectron2]: [0mRunning with full config:
CUDNN_BENCHMARK: False
DATALOADER:
  ASPECT_RATIO_GROUPING: True
  FILTER_EMPTY_ANNOTATIONS: True
  NUM_WORKERS: 8
  REPEAT_THRESHOLD: 0.0
  SAMPLER_TRAIN: TrainingSampler
DATASETS:
  PRECOMPUTED_PROPOSAL_TOPK_TEST: 1000
  PRECOMPUTED_PROPOSAL_TOPK_TRAIN: 2000
  PROPOSAL_FILES_TEST: ()
  PROPOSAL_FILES_TRAIN: ()
  TEST: ('coco_2017_val',)
  TRAIN: ('coco_2017_train_voc_10_shot',)
GLOBAL:
  HACK: 1.0
INPUT:
  CROP:
    ENABLED: False
    SIZE: [0.9, 0.9]
    TYPE: relative_range
  FORMAT: BGR
  FS:
    FEW_SHOT: True
    SUPPORT_SHOT: 9
    SUPPORT_WAY: 2
  MASK_FORMAT: polygon
  MAX_SIZE_TEST: 1000
  MAX_SIZE_TRAIN: 1000
  MIN_SIZE_TEST: 600
  MIN_SIZE_TRAIN: (440, 472, 504, 536, 568, 600)
  MIN_SIZE_TRAIN_SAMPLING: choice
MODEL:
  ANCHOR_GENERATOR:
    ANGLES: [[-90, 0, 90]]
    ASPECT_RATIOS: [[0.5, 1.0, 2.0]]
    NAME: DefaultAnchorGenerator
    OFFSET: 0.0
    SIZES: [[32, 64, 128, 256, 512]]
  BACKBONE:
    FREEZE_AT: 5
    NAME: build_resnet_backbone
  DEVICE: cuda
  FPN:
    FUSE_TYPE: sum
    IN_FEATURES: []
    NORM: 
    OUT_CHANNELS: 256
  KEYPOINT_ON: False
  LOAD_PROPOSALS: False
  MASK_ON: False
  META_ARCHITECTURE: FsodRCNN
  PANOPTIC_FPN:
    COMBINE:
      ENABLED: True
      INSTANCES_CONFIDENCE_THRESH: 0.5
      OVERLAP_THRESH: 0.5
      STUFF_AREA_LIMIT: 4096
    INSTANCE_LOSS_WEIGHT: 1.0
  PIXEL_MEAN: [103.53, 116.28, 123.675]
  PIXEL_STD: [1.0, 1.0, 1.0]
  PROPOSAL_GENERATOR:
    MIN_SIZE: 0
    NAME: FsodRPN
  RESNETS:
    DEFORM_MODULATED: False
    DEFORM_NUM_GROUPS: 1
    DEFORM_ON_PER_STAGE: [False, False, False, False]
    DEPTH: 50
    NORM: FrozenBN
    NUM_GROUPS: 1
    OUT_FEATURES: ['res4']
    RES2_OUT_CHANNELS: 256
    RES5_DILATION: 1
    STEM_OUT_CHANNELS: 64
    STRIDE_IN_1X1: True
    WIDTH_PER_GROUP: 64
  RETINANET:
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    FOCAL_LOSS_ALPHA: 0.25
    FOCAL_LOSS_GAMMA: 2.0
    IN_FEATURES: ['p3', 'p4', 'p5', 'p6', 'p7']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.4, 0.5]
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 80
    NUM_CONVS: 4
    PRIOR_PROB: 0.01
    SCORE_THRESH_TEST: 0.05
    SMOOTH_L1_LOSS_BETA: 0.1
    TOPK_CANDIDATES_TEST: 1000
  ROI_BOX_CASCADE_HEAD:
    BBOX_REG_WEIGHTS: ((10.0, 10.0, 5.0, 5.0), (20.0, 20.0, 10.0, 10.0), (30.0, 30.0, 15.0, 15.0))
    IOUS: (0.5, 0.6, 0.7)
  ROI_BOX_HEAD:
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (10.0, 10.0, 5.0, 5.0)
    CLS_AGNOSTIC_BBOX_REG: False
    CONV_DIM: 256
    FC_DIM: 1024
    NAME: 
    NORM: 
    NUM_CONV: 0
    NUM_FC: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
    SMOOTH_L1_BETA: 0.0
    TRAIN_ON_PRED_BOXES: False
  ROI_HEADS:
    BATCH_SIZE_PER_IMAGE: 128
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, 1]
    IOU_THRESHOLDS: [0.5]
    NAME: FsodRes5ROIHeads
    NMS_THRESH_TEST: 0.5
    NUM_CLASSES: 1
    POSITIVE_FRACTION: 0.5
    PROPOSAL_APPEND_GT: True
    SCORE_THRESH_TEST: 0.05
  ROI_KEYPOINT_HEAD:
    CONV_DIMS: (512, 512, 512, 512, 512, 512, 512, 512)
    LOSS_WEIGHT: 1.0
    MIN_KEYPOINTS_PER_IMAGE: 1
    NAME: KRCNNConvDeconvUpsampleHead
    NORMALIZE_LOSS_BY_VISIBLE_KEYPOINTS: True
    NUM_KEYPOINTS: 17
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  ROI_MASK_HEAD:
    CLS_AGNOSTIC_MASK: False
    CONV_DIM: 256
    NAME: MaskRCNNConvUpsampleHead
    NORM: 
    NUM_CONV: 0
    POOLER_RESOLUTION: 14
    POOLER_SAMPLING_RATIO: 0
    POOLER_TYPE: ROIAlignV2
  RPN:
    BATCH_SIZE_PER_IMAGE: 256
    BBOX_REG_LOSS_TYPE: smooth_l1
    BBOX_REG_LOSS_WEIGHT: 1.0
    BBOX_REG_WEIGHTS: (1.0, 1.0, 1.0, 1.0)
    BOUNDARY_THRESH: -1
    HEAD_NAME: StandardRPNHead
    IN_FEATURES: ['res4']
    IOU_LABELS: [0, -1, 1]
    IOU_THRESHOLDS: [0.3, 0.7]
    LOSS_WEIGHT: 1.0
    NMS_THRESH: 0.7
    POSITIVE_FRACTION: 0.5
    POST_NMS_TOPK_TEST: 100
    POST_NMS_TOPK_TRAIN: 2000
    PRE_NMS_TOPK_TEST: 6000
    PRE_NMS_TOPK_TRAIN: 12000
    SMOOTH_L1_BETA: 0.0
  SEM_SEG_HEAD:
    COMMON_STRIDE: 4
    CONVS_DIM: 128
    IGNORE_VALUE: 255
    IN_FEATURES: ['p2', 'p3', 'p4', 'p5']
    LOSS_WEIGHT: 1.0
    NAME: SemSegFPNHead
    NORM: GN
    NUM_CLASSES: 54
  WEIGHTS: ./output/fsod/finetune_dir/R_50_C4_1x/model_final.pth
OUTPUT_DIR: ./output/fsod/finetune_dir/R_50_C4_1x
SEED: -1
SOLVER:
  BASE_LR: 0.001
  BIAS_LR_FACTOR: 1.0
  CHECKPOINT_PERIOD: 60000
  CLIP_GRADIENTS:
    CLIP_TYPE: value
    CLIP_VALUE: 1.0
    ENABLED: False
    NORM_TYPE: 2.0
  GAMMA: 0.1
  HEAD_LR_FACTOR: 2.0
  IMS_PER_BATCH: 4
  LR_SCHEDULER_NAME: WarmupMultiStepLR
  MAX_ITER: 3000
  MOMENTUM: 0.9
  NESTEROV: False
  REFERENCE_WORLD_SIZE: 0
  STEPS: (2000, 3000)
  WARMUP_FACTOR: 0.1
  WARMUP_ITERS: 200
  WARMUP_METHOD: linear
  WEIGHT_DECAY: 0.0001
  WEIGHT_DECAY_BIAS: 0.0001
  WEIGHT_DECAY_NORM: 0.0
TEST:
  AUG:
    ENABLED: False
    FLIP: True
    MAX_SIZE: 4000
    MIN_SIZES: (400, 500, 600, 700, 800, 900, 1000, 1100, 1200)
  DETECTIONS_PER_IMAGE: 100
  EVAL_PERIOD: 0
  EXPECTED_RESULTS: []
  KEYPOINT_OKS_SIGMAS: []
  PRECISE_BN:
    ENABLED: False
    NUM_ITER: 200
VERSION: 2
VIS_PERIOD: 0
[32m[10/15 23:59:18 detectron2]: [0mFull config saved to ./output/fsod/finetune_dir/R_50_C4_1x/config.yaml
[32m[10/15 23:59:18 d2.utils.env]: [0mUsing a generated random seed 18883410
[5m[31mWARNING[0m [32m[10/15 23:59:18 d2.modeling.backbone.resnet]: [0mResNet.make_stage(first_stride=) is deprecated!  Use 'stride_per_block' or 'stride' instead.
[32m[10/15 23:59:19 d2.engine.defaults]: [0mModel:
FsodRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): FsodRPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(1024, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(1024, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): FsodRes5ROIHeads(
    (pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
    (box_predictor): FsodFastRCNNOutputLayers(
      (conv_1): Conv2d(4096, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), bias=False)
      (conv_3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (bbox_pred_pr): Linear(in_features=2048, out_features=4, bias=True)
      (cls_score_pr): Linear(in_features=2048, out_features=2, bias=True)
      (conv_cor): Conv2d(2048, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)
      (cls_score_cor): Linear(in_features=2048, out_features=2, bias=True)
      (fc_1): Linear(in_features=4096, out_features=2048, bias=True)
      (fc_2): Linear(in_features=2048, out_features=2048, bias=True)
      (cls_score_fc): Linear(in_features=2048, out_features=2, bias=True)
      (avgpool): AvgPool2d(kernel_size=3, stride=1, padding=0)
      (avgpool_fc): AvgPool2d(kernel_size=7, stride=7, padding=0)
    )
  )
)
[32m[10/15 23:59:19 fvcore.common.checkpoint]: [0mLoading checkpoint from ./output/fsod/finetune_dir/R_50_C4_1x/model_final.pth
[32m[10/15 23:59:19 d2.data.datasets.coco]: [0mLoaded 5000 images in COCO format from datasets/coco/annotations/instances_val2017.json
[32m[10/15 23:59:20 d2.data.build]: [0mDistribution of instances among all 80 categories:
[36m|   category    | #instances   |   category   | #instances   |   category    | #instances   |
|:-------------:|:-------------|:------------:|:-------------|:-------------:|:-------------|
|    person     | 10777        |   bicycle    | 314          |      car      | 1918         |
|  motorcycle   | 367          |   airplane   | 143          |      bus      | 283          |
|     train     | 190          |    truck     | 414          |     boat      | 424          |
| traffic light | 634          | fire hydrant | 101          |   stop sign   | 75           |
| parking meter | 60           |    bench     | 411          |     bird      | 427          |
|      cat      | 202          |     dog      | 218          |     horse     | 272          |
|     sheep     | 354          |     cow      | 372          |   elephant    | 252          |
|     bear      | 71           |    zebra     | 266          |    giraffe    | 232          |
|   backpack    | 371          |   umbrella   | 407          |    handbag    | 540          |
|      tie      | 252          |   suitcase   | 299          |    frisbee    | 115          |
|     skis      | 241          |  snowboard   | 69           |  sports ball  | 260          |
|     kite      | 327          | baseball bat | 145          | baseball gl.. | 148          |
|  skateboard   | 179          |  surfboard   | 267          | tennis racket | 225          |
|    bottle     | 1013         |  wine glass  | 341          |      cup      | 895          |
|     fork      | 215          |    knife     | 325          |     spoon     | 253          |
|     bowl      | 623          |    banana    | 370          |     apple     | 236          |
|   sandwich    | 177          |    orange    | 285          |   broccoli    | 312          |
|    carrot     | 365          |   hot dog    | 125          |     pizza     | 284          |
|     donut     | 328          |     cake     | 310          |     chair     | 1771         |
|     couch     | 261          | potted plant | 342          |      bed      | 163          |
| dining table  | 695          |    toilet    | 179          |      tv       | 288          |
|    laptop     | 231          |    mouse     | 106          |    remote     | 283          |
|   keyboard    | 153          |  cell phone  | 262          |   microwave   | 55           |
|     oven      | 143          |   toaster    | 9            |     sink      | 225          |
| refrigerator  | 126          |     book     | 1129         |     clock     | 267          |
|     vase      | 274          |   scissors   | 36           |  teddy bear   | 190          |
|  hair drier   | 11           |  toothbrush  | 57           |               |              |
|     total     | 36335        |              |              |               |              |[0m
[32m[10/15 23:59:20 d2.data.common]: [0mSerializing 5000 elements to byte tensors and concatenating them all ...
[32m[10/15 23:59:20 d2.data.common]: [0mSerialized dataset takes 19.10 MiB
[32m[10/15 23:59:20 d2.data.dataset_mapper]: [0mAugmentations used in training: [ResizeShortestEdge(short_edge_length=(600, 600), max_size=1000, sample_style='choice')]
[32m[10/15 23:59:20 d2.evaluation.evaluator]: [0mStart inference on 2500 images
/home/liuwj/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
/home/liuwj/anaconda3/lib/python3.8/site-packages/setuptools/distutils_patch.py:25: UserWarning: Distutils was imported before Setuptools. This usage is discouraged and may exhibit undesirable behaviors or errors. Please use Setuptools' objects directly or at least import Setuptools first.
  warnings.warn(
[32m[10/15 23:59:36 d2.evaluation.evaluator]: [0mInference done 11/2500. 0.6467 s / img. ETA=0:26:51
[32m[10/15 23:59:41 d2.evaluation.evaluator]: [0mInference done 20/2500. 0.6201 s / img. ETA=0:25:39
[32m[10/15 23:59:47 d2.evaluation.evaluator]: [0mInference done 29/2500. 0.6206 s / img. ETA=0:25:35
[32m[10/15 23:59:52 d2.evaluation.evaluator]: [0mInference done 37/2500. 0.6221 s / img. ETA=0:25:34
[32m[10/15 23:59:57 d2.evaluation.evaluator]: [0mInference done 45/2500. 0.6299 s / img. ETA=0:25:48
[32m[10/16 00:00:03 d2.evaluation.evaluator]: [0mInference done 53/2500. 0.6344 s / img. ETA=0:25:54
[32m[10/16 00:00:08 d2.evaluation.evaluator]: [0mInference done 61/2500. 0.6415 s / img. ETA=0:26:06
[32m[10/16 00:00:14 d2.evaluation.evaluator]: [0mInference done 69/2500. 0.6506 s / img. ETA=0:26:23
[32m[10/16 00:00:19 d2.evaluation.evaluator]: [0mInference done 76/2500. 0.6570 s / img. ETA=0:26:34
[32m[10/16 00:00:24 d2.evaluation.evaluator]: [0mInference done 83/2500. 0.6632 s / img. ETA=0:26:44
[32m[10/16 00:00:29 d2.evaluation.evaluator]: [0mInference done 90/2500. 0.6675 s / img. ETA=0:26:50
[32m[10/16 00:00:34 d2.evaluation.evaluator]: [0mInference done 97/2500. 0.6733 s / img. ETA=0:26:59
[32m[10/16 00:00:39 d2.evaluation.evaluator]: [0mInference done 104/2500. 0.6793 s / img. ETA=0:27:09
[32m[10/16 00:00:45 d2.evaluation.evaluator]: [0mInference done 111/2500. 0.6847 s / img. ETA=0:27:17
[32m[10/16 00:00:50 d2.evaluation.evaluator]: [0mInference done 118/2500. 0.6905 s / img. ETA=0:27:26
[32m[10/16 00:00:56 d2.evaluation.evaluator]: [0mInference done 125/2500. 0.6969 s / img. ETA=0:27:37
[32m[10/16 00:01:01 d2.evaluation.evaluator]: [0mInference done 131/2500. 0.7039 s / img. ETA=0:27:49
[32m[10/16 00:01:06 d2.evaluation.evaluator]: [0mInference done 137/2500. 0.7102 s / img. ETA=0:28:00
[32m[10/16 00:01:11 d2.evaluation.evaluator]: [0mInference done 143/2500. 0.7160 s / img. ETA=0:28:09
[32m[10/16 00:01:17 d2.evaluation.evaluator]: [0mInference done 150/2500. 0.7195 s / img. ETA=0:28:12
[32m[10/16 00:01:22 d2.evaluation.evaluator]: [0mInference done 157/2500. 0.7225 s / img. ETA=0:28:14
[32m[10/16 00:01:28 d2.evaluation.evaluator]: [0mInference done 164/2500. 0.7252 s / img. ETA=0:28:16
[32m[10/16 00:01:33 d2.evaluation.evaluator]: [0mInference done 171/2500. 0.7293 s / img. ETA=0:28:20
[32m[10/16 00:01:39 d2.evaluation.evaluator]: [0mInference done 178/2500. 0.7332 s / img. ETA=0:28:24
[32m[10/16 00:01:45 d2.evaluation.evaluator]: [0mInference done 185/2500. 0.7370 s / img. ETA=0:28:28
[32m[10/16 00:01:51 d2.evaluation.evaluator]: [0mInference done 192/2500. 0.7398 s / img. ETA=0:28:29
[32m[10/16 00:01:56 d2.evaluation.evaluator]: [0mInference done 198/2500. 0.7430 s / img. ETA=0:28:32
[32m[10/16 00:02:01 d2.evaluation.evaluator]: [0mInference done 204/2500. 0.7463 s / img. ETA=0:28:35
[32m[10/16 00:02:06 d2.evaluation.evaluator]: [0mInference done 210/2500. 0.7492 s / img. ETA=0:28:37
[32m[10/16 00:02:12 d2.evaluation.evaluator]: [0mInference done 217/2500. 0.7519 s / img. ETA=0:28:38
[32m[10/16 00:02:17 d2.evaluation.evaluator]: [0mInference done 223/2500. 0.7542 s / img. ETA=0:28:39
[32m[10/16 00:02:22 d2.evaluation.evaluator]: [0mInference done 229/2500. 0.7583 s / img. ETA=0:28:44
[32m[10/16 00:02:28 d2.evaluation.evaluator]: [0mInference done 235/2500. 0.7623 s / img. ETA=0:28:48
[32m[10/16 00:02:33 d2.evaluation.evaluator]: [0mInference done 241/2500. 0.7644 s / img. ETA=0:28:48
[32m[10/16 00:02:38 d2.evaluation.evaluator]: [0mInference done 247/2500. 0.7675 s / img. ETA=0:28:51
[32m[10/16 00:02:43 d2.evaluation.evaluator]: [0mInference done 253/2500. 0.7710 s / img. ETA=0:28:54
[32m[10/16 00:02:49 d2.evaluation.evaluator]: [0mInference done 259/2500. 0.7744 s / img. ETA=0:28:57
[32m[10/16 00:02:54 d2.evaluation.evaluator]: [0mInference done 265/2500. 0.7765 s / img. ETA=0:28:57
[32m[10/16 00:03:00 d2.evaluation.evaluator]: [0mInference done 272/2500. 0.7779 s / img. ETA=0:28:55
[32m[10/16 00:03:06 d2.evaluation.evaluator]: [0mInference done 279/2500. 0.7787 s / img. ETA=0:28:51
[32m[10/16 00:03:11 d2.evaluation.evaluator]: [0mInference done 285/2500. 0.7804 s / img. ETA=0:28:50
[32m[10/16 00:03:16 d2.evaluation.evaluator]: [0mInference done 291/2500. 0.7820 s / img. ETA=0:28:49
[32m[10/16 00:03:21 d2.evaluation.evaluator]: [0mInference done 297/2500. 0.7836 s / img. ETA=0:28:48
[32m[10/16 00:03:27 d2.evaluation.evaluator]: [0mInference done 304/2500. 0.7848 s / img. ETA=0:28:45
[32m[10/16 00:03:32 d2.evaluation.evaluator]: [0mInference done 310/2500. 0.7867 s / img. ETA=0:28:44
[32m[10/16 00:03:38 d2.evaluation.evaluator]: [0mInference done 316/2500. 0.7888 s / img. ETA=0:28:44
[32m[10/16 00:03:43 d2.evaluation.evaluator]: [0mInference done 322/2500. 0.7906 s / img. ETA=0:28:43
[32m[10/16 00:03:48 d2.evaluation.evaluator]: [0mInference done 328/2500. 0.7923 s / img. ETA=0:28:42
[32m[10/16 00:03:54 d2.evaluation.evaluator]: [0mInference done 334/2500. 0.7939 s / img. ETA=0:28:41
[32m[10/16 00:03:59 d2.evaluation.evaluator]: [0mInference done 340/2500. 0.7954 s / img. ETA=0:28:39
[32m[10/16 00:04:04 d2.evaluation.evaluator]: [0mInference done 346/2500. 0.7969 s / img. ETA=0:28:38
[32m[10/16 00:04:09 d2.evaluation.evaluator]: [0mInference done 352/2500. 0.7985 s / img. ETA=0:28:37
[32m[10/16 00:04:15 d2.evaluation.evaluator]: [0mInference done 359/2500. 0.7995 s / img. ETA=0:28:33
[32m[10/16 00:04:21 d2.evaluation.evaluator]: [0mInference done 365/2500. 0.8020 s / img. ETA=0:28:34
[32m[10/16 00:04:27 d2.evaluation.evaluator]: [0mInference done 371/2500. 0.8043 s / img. ETA=0:28:34
[32m[10/16 00:04:32 d2.evaluation.evaluator]: [0mInference done 377/2500. 0.8061 s / img. ETA=0:28:33
[32m[10/16 00:04:38 d2.evaluation.evaluator]: [0mInference done 383/2500. 0.8074 s / img. ETA=0:28:31
[32m[10/16 00:04:43 d2.evaluation.evaluator]: [0mInference done 390/2500. 0.8079 s / img. ETA=0:28:26
[32m[10/16 00:04:48 d2.evaluation.evaluator]: [0mInference done 396/2500. 0.8083 s / img. ETA=0:28:22
[32m[10/16 00:04:54 d2.evaluation.evaluator]: [0mInference done 402/2500. 0.8088 s / img. ETA=0:28:18
[32m[10/16 00:04:59 d2.evaluation.evaluator]: [0mInference done 408/2500. 0.8093 s / img. ETA=0:28:15
[32m[10/16 00:05:04 d2.evaluation.evaluator]: [0mInference done 415/2500. 0.8098 s / img. ETA=0:28:10
[32m[10/16 00:05:10 d2.evaluation.evaluator]: [0mInference done 421/2500. 0.8112 s / img. ETA=0:28:08
[32m[10/16 00:05:16 d2.evaluation.evaluator]: [0mInference done 428/2500. 0.8111 s / img. ETA=0:28:02
[32m[10/16 00:05:21 d2.evaluation.evaluator]: [0mInference done 435/2500. 0.8111 s / img. ETA=0:27:56
[32m[10/16 00:05:27 d2.evaluation.evaluator]: [0mInference done 441/2500. 0.8128 s / img. ETA=0:27:55
[32m[10/16 00:05:32 d2.evaluation.evaluator]: [0mInference done 447/2500. 0.8144 s / img. ETA=0:27:53
[32m[10/16 00:05:38 d2.evaluation.evaluator]: [0mInference done 453/2500. 0.8153 s / img. ETA=0:27:50
[32m[10/16 00:05:43 d2.evaluation.evaluator]: [0mInference done 459/2500. 0.8157 s / img. ETA=0:27:46
[32m[10/16 00:05:49 d2.evaluation.evaluator]: [0mInference done 466/2500. 0.8160 s / img. ETA=0:27:41
[32m[10/16 00:05:54 d2.evaluation.evaluator]: [0mInference done 473/2500. 0.8162 s / img. ETA=0:27:36
[32m[10/16 00:06:00 d2.evaluation.evaluator]: [0mInference done 479/2500. 0.8180 s / img. ETA=0:27:35
[32m[10/16 00:06:06 d2.evaluation.evaluator]: [0mInference done 485/2500. 0.8190 s / img. ETA=0:27:32
[32m[10/16 00:06:11 d2.evaluation.evaluator]: [0mInference done 491/2500. 0.8202 s / img. ETA=0:27:29
[32m[10/16 00:06:17 d2.evaluation.evaluator]: [0mInference done 497/2500. 0.8212 s / img. ETA=0:27:26
[32m[10/16 00:06:22 d2.evaluation.evaluator]: [0mInference done 503/2500. 0.8219 s / img. ETA=0:27:23
[32m[10/16 00:06:27 d2.evaluation.evaluator]: [0mInference done 509/2500. 0.8225 s / img. ETA=0:27:19
[32m[10/16 00:06:32 d2.evaluation.evaluator]: [0mInference done 515/2500. 0.8232 s / img. ETA=0:27:15
[32m[10/16 00:06:38 d2.evaluation.evaluator]: [0mInference done 521/2500. 0.8237 s / img. ETA=0:27:11
[32m[10/16 00:06:43 d2.evaluation.evaluator]: [0mInference done 528/2500. 0.8239 s / img. ETA=0:27:06
[32m[10/16 00:06:49 d2.evaluation.evaluator]: [0mInference done 534/2500. 0.8246 s / img. ETA=0:27:02
[32m[10/16 00:06:54 d2.evaluation.evaluator]: [0mInference done 540/2500. 0.8253 s / img. ETA=0:26:59
[32m[10/16 00:06:59 d2.evaluation.evaluator]: [0mInference done 546/2500. 0.8259 s / img. ETA=0:26:55
[32m[10/16 00:07:05 d2.evaluation.evaluator]: [0mInference done 552/2500. 0.8263 s / img. ETA=0:26:51
[32m[10/16 00:07:10 d2.evaluation.evaluator]: [0mInference done 558/2500. 0.8265 s / img. ETA=0:26:46
[32m[10/16 00:07:15 d2.evaluation.evaluator]: [0mInference done 564/2500. 0.8270 s / img. ETA=0:26:42
[32m[10/16 00:07:20 d2.evaluation.evaluator]: [0mInference done 570/2500. 0.8282 s / img. ETA=0:26:40
[32m[10/16 00:07:26 d2.evaluation.evaluator]: [0mInference done 576/2500. 0.8289 s / img. ETA=0:26:36
[32m[10/16 00:07:31 d2.evaluation.evaluator]: [0mInference done 582/2500. 0.8295 s / img. ETA=0:26:32
[32m[10/16 00:07:36 d2.evaluation.evaluator]: [0mInference done 588/2500. 0.8296 s / img. ETA=0:26:27
[32m[10/16 00:07:42 d2.evaluation.evaluator]: [0mInference done 594/2500. 0.8304 s / img. ETA=0:26:24
[32m[10/16 00:07:47 d2.evaluation.evaluator]: [0mInference done 600/2500. 0.8313 s / img. ETA=0:26:21
[32m[10/16 00:07:53 d2.evaluation.evaluator]: [0mInference done 606/2500. 0.8320 s / img. ETA=0:26:17
[32m[10/16 00:07:58 d2.evaluation.evaluator]: [0mInference done 612/2500. 0.8321 s / img. ETA=0:26:12
[32m[10/16 00:08:03 d2.evaluation.evaluator]: [0mInference done 618/2500. 0.8323 s / img. ETA=0:26:08
[32m[10/16 00:08:08 d2.evaluation.evaluator]: [0mInference done 624/2500. 0.8333 s / img. ETA=0:26:04
[32m[10/16 00:08:14 d2.evaluation.evaluator]: [0mInference done 630/2500. 0.8334 s / img. ETA=0:26:00
[32m[10/16 00:08:19 d2.evaluation.evaluator]: [0mInference done 637/2500. 0.8335 s / img. ETA=0:25:54
[32m[10/16 00:08:24 d2.evaluation.evaluator]: [0mInference done 643/2500. 0.8336 s / img. ETA=0:25:49
[32m[10/16 00:08:30 d2.evaluation.evaluator]: [0mInference done 650/2500. 0.8334 s / img. ETA=0:25:43
[32m[10/16 00:08:35 d2.evaluation.evaluator]: [0mInference done 656/2500. 0.8338 s / img. ETA=0:25:39
[32m[10/16 00:08:41 d2.evaluation.evaluator]: [0mInference done 662/2500. 0.8340 s / img. ETA=0:25:34
[32m[10/16 00:08:46 d2.evaluation.evaluator]: [0mInference done 668/2500. 0.8342 s / img. ETA=0:25:29
[32m[10/16 00:08:51 d2.evaluation.evaluator]: [0mInference done 674/2500. 0.8346 s / img. ETA=0:25:25
[32m[10/16 00:08:56 d2.evaluation.evaluator]: [0mInference done 680/2500. 0.8347 s / img. ETA=0:25:20
[32m[10/16 00:09:01 d2.evaluation.evaluator]: [0mInference done 686/2500. 0.8349 s / img. ETA=0:25:16
[32m[10/16 00:09:07 d2.evaluation.evaluator]: [0mInference done 692/2500. 0.8353 s / img. ETA=0:25:11
[32m[10/16 00:09:12 d2.evaluation.evaluator]: [0mInference done 698/2500. 0.8356 s / img. ETA=0:25:07
[32m[10/16 00:09:17 d2.evaluation.evaluator]: [0mInference done 704/2500. 0.8358 s / img. ETA=0:25:02
[32m[10/16 00:09:22 d2.evaluation.evaluator]: [0mInference done 710/2500. 0.8361 s / img. ETA=0:24:58
[32m[10/16 00:09:27 d2.evaluation.evaluator]: [0mInference done 716/2500. 0.8366 s / img. ETA=0:24:54
[32m[10/16 00:09:33 d2.evaluation.evaluator]: [0mInference done 722/2500. 0.8371 s / img. ETA=0:24:49
[32m[10/16 00:09:38 d2.evaluation.evaluator]: [0mInference done 728/2500. 0.8376 s / img. ETA=0:24:45
[32m[10/16 00:09:43 d2.evaluation.evaluator]: [0mInference done 734/2500. 0.8377 s / img. ETA=0:24:40
[32m[10/16 00:09:49 d2.evaluation.evaluator]: [0mInference done 741/2500. 0.8375 s / img. ETA=0:24:34
[32m[10/16 00:09:54 d2.evaluation.evaluator]: [0mInference done 747/2500. 0.8379 s / img. ETA=0:24:30
[32m[10/16 00:10:00 d2.evaluation.evaluator]: [0mInference done 754/2500. 0.8379 s / img. ETA=0:24:24
[32m[10/16 00:10:06 d2.evaluation.evaluator]: [0mInference done 760/2500. 0.8384 s / img. ETA=0:24:20
[32m[10/16 00:10:11 d2.evaluation.evaluator]: [0mInference done 766/2500. 0.8389 s / img. ETA=0:24:16
[32m[10/16 00:10:17 d2.evaluation.evaluator]: [0mInference done 773/2500. 0.8389 s / img. ETA=0:24:10
[32m[10/16 00:10:22 d2.evaluation.evaluator]: [0mInference done 779/2500. 0.8392 s / img. ETA=0:24:05
[32m[10/16 00:10:28 d2.evaluation.evaluator]: [0mInference done 785/2500. 0.8397 s / img. ETA=0:24:01
[32m[10/16 00:10:33 d2.evaluation.evaluator]: [0mInference done 791/2500. 0.8396 s / img. ETA=0:23:56
[32m[10/16 00:10:38 d2.evaluation.evaluator]: [0mInference done 798/2500. 0.8392 s / img. ETA=0:23:49
[32m[10/16 00:10:43 d2.evaluation.evaluator]: [0mInference done 804/2500. 0.8393 s / img. ETA=0:23:45
[32m[10/16 00:10:49 d2.evaluation.evaluator]: [0mInference done 811/2500. 0.8392 s / img. ETA=0:23:38
[32m[10/16 00:10:54 d2.evaluation.evaluator]: [0mInference done 817/2500. 0.8392 s / img. ETA=0:23:33
[32m[10/16 00:10:59 d2.evaluation.evaluator]: [0mInference done 823/2500. 0.8393 s / img. ETA=0:23:28
[32m[10/16 00:11:04 d2.evaluation.evaluator]: [0mInference done 829/2500. 0.8394 s / img. ETA=0:23:24
[32m[10/16 00:11:10 d2.evaluation.evaluator]: [0mInference done 836/2500. 0.8391 s / img. ETA=0:23:17
[32m[10/16 00:11:16 d2.evaluation.evaluator]: [0mInference done 843/2500. 0.8389 s / img. ETA=0:23:11
[32m[10/16 00:11:22 d2.evaluation.evaluator]: [0mInference done 850/2500. 0.8387 s / img. ETA=0:23:05
[32m[10/16 00:11:27 d2.evaluation.evaluator]: [0mInference done 857/2500. 0.8384 s / img. ETA=0:22:59
[32m[10/16 00:11:33 d2.evaluation.evaluator]: [0mInference done 864/2500. 0.8382 s / img. ETA=0:22:52
[32m[10/16 00:11:38 d2.evaluation.evaluator]: [0mInference done 870/2500. 0.8383 s / img. ETA=0:22:47
[32m[10/16 00:11:44 d2.evaluation.evaluator]: [0mInference done 877/2500. 0.8380 s / img. ETA=0:22:41
[32m[10/16 00:11:49 d2.evaluation.evaluator]: [0mInference done 884/2500. 0.8375 s / img. ETA=0:22:34
[32m[10/16 00:11:55 d2.evaluation.evaluator]: [0mInference done 891/2500. 0.8373 s / img. ETA=0:22:28
[32m[10/16 00:12:00 d2.evaluation.evaluator]: [0mInference done 898/2500. 0.8369 s / img. ETA=0:22:22
[32m[10/16 00:12:06 d2.evaluation.evaluator]: [0mInference done 905/2500. 0.8364 s / img. ETA=0:22:15
[32m[10/16 00:12:11 d2.evaluation.evaluator]: [0mInference done 912/2500. 0.8359 s / img. ETA=0:22:08
[32m[10/16 00:12:17 d2.evaluation.evaluator]: [0mInference done 919/2500. 0.8357 s / img. ETA=0:22:02
[32m[10/16 00:12:22 d2.evaluation.evaluator]: [0mInference done 926/2500. 0.8356 s / img. ETA=0:21:56
[32m[10/16 00:12:28 d2.evaluation.evaluator]: [0mInference done 933/2500. 0.8355 s / img. ETA=0:21:50
[32m[10/16 00:12:34 d2.evaluation.evaluator]: [0mInference done 940/2500. 0.8353 s / img. ETA=0:21:44
[32m[10/16 00:12:39 d2.evaluation.evaluator]: [0mInference done 947/2500. 0.8347 s / img. ETA=0:21:37
[32m[10/16 00:12:44 d2.evaluation.evaluator]: [0mInference done 954/2500. 0.8340 s / img. ETA=0:21:30
[32m[10/16 00:12:50 d2.evaluation.evaluator]: [0mInference done 961/2500. 0.8339 s / img. ETA=0:21:24
[32m[10/16 00:12:56 d2.evaluation.evaluator]: [0mInference done 968/2500. 0.8337 s / img. ETA=0:21:18
[32m[10/16 00:13:01 d2.evaluation.evaluator]: [0mInference done 975/2500. 0.8332 s / img. ETA=0:21:12
[32m[10/16 00:13:07 d2.evaluation.evaluator]: [0mInference done 982/2500. 0.8331 s / img. ETA=0:21:05
[32m[10/16 00:13:13 d2.evaluation.evaluator]: [0mInference done 989/2500. 0.8330 s / img. ETA=0:20:59
[32m[10/16 00:13:18 d2.evaluation.evaluator]: [0mInference done 996/2500. 0.8328 s / img. ETA=0:20:53
[32m[10/16 00:13:24 d2.evaluation.evaluator]: [0mInference done 1003/2500. 0.8325 s / img. ETA=0:20:47
[32m[10/16 00:13:29 d2.evaluation.evaluator]: [0mInference done 1010/2500. 0.8322 s / img. ETA=0:20:41
[32m[10/16 00:13:35 d2.evaluation.evaluator]: [0mInference done 1017/2500. 0.8320 s / img. ETA=0:20:35
[32m[10/16 00:13:41 d2.evaluation.evaluator]: [0mInference done 1024/2500. 0.8318 s / img. ETA=0:20:29
[32m[10/16 00:13:46 d2.evaluation.evaluator]: [0mInference done 1031/2500. 0.8316 s / img. ETA=0:20:22
[32m[10/16 00:13:52 d2.evaluation.evaluator]: [0mInference done 1038/2500. 0.8315 s / img. ETA=0:20:16
[32m[10/16 00:13:58 d2.evaluation.evaluator]: [0mInference done 1045/2500. 0.8313 s / img. ETA=0:20:10
[32m[10/16 00:14:03 d2.evaluation.evaluator]: [0mInference done 1052/2500. 0.8312 s / img. ETA=0:20:04
[32m[10/16 00:14:09 d2.evaluation.evaluator]: [0mInference done 1059/2500. 0.8309 s / img. ETA=0:19:58
[32m[10/16 00:14:14 d2.evaluation.evaluator]: [0mInference done 1066/2500. 0.8305 s / img. ETA=0:19:52
[32m[10/16 00:14:20 d2.evaluation.evaluator]: [0mInference done 1073/2500. 0.8302 s / img. ETA=0:19:46
[32m[10/16 00:14:25 d2.evaluation.evaluator]: [0mInference done 1080/2500. 0.8298 s / img. ETA=0:19:39
[32m[10/16 00:14:30 d2.evaluation.evaluator]: [0mInference done 1087/2500. 0.8294 s / img. ETA=0:19:33
[32m[10/16 00:14:35 d2.evaluation.evaluator]: [0mInference done 1093/2500. 0.8294 s / img. ETA=0:19:28
[32m[10/16 00:14:41 d2.evaluation.evaluator]: [0mInference done 1100/2500. 0.8291 s / img. ETA=0:19:21
[32m[10/16 00:14:46 d2.evaluation.evaluator]: [0mInference done 1106/2500. 0.8291 s / img. ETA=0:19:17
[32m[10/16 00:14:51 d2.evaluation.evaluator]: [0mInference done 1113/2500. 0.8289 s / img. ETA=0:19:10
[32m[10/16 00:14:57 d2.evaluation.evaluator]: [0mInference done 1120/2500. 0.8287 s / img. ETA=0:19:04
[32m[10/16 00:15:03 d2.evaluation.evaluator]: [0mInference done 1127/2500. 0.8284 s / img. ETA=0:18:58
[32m[10/16 00:15:08 d2.evaluation.evaluator]: [0mInference done 1134/2500. 0.8279 s / img. ETA=0:18:52
[32m[10/16 00:15:13 d2.evaluation.evaluator]: [0mInference done 1141/2500. 0.8277 s / img. ETA=0:18:46
[32m[10/16 00:15:19 d2.evaluation.evaluator]: [0mInference done 1148/2500. 0.8274 s / img. ETA=0:18:39
[32m[10/16 00:15:24 d2.evaluation.evaluator]: [0mInference done 1155/2500. 0.8272 s / img. ETA=0:18:33
[32m[10/16 00:15:30 d2.evaluation.evaluator]: [0mInference done 1162/2500. 0.8270 s / img. ETA=0:18:27
[32m[10/16 00:15:35 d2.evaluation.evaluator]: [0mInference done 1169/2500. 0.8268 s / img. ETA=0:18:21
[32m[10/16 00:15:41 d2.evaluation.evaluator]: [0mInference done 1176/2500. 0.8264 s / img. ETA=0:18:15
[32m[10/16 00:15:46 d2.evaluation.evaluator]: [0mInference done 1183/2500. 0.8260 s / img. ETA=0:18:08
[32m[10/16 00:15:51 d2.evaluation.evaluator]: [0mInference done 1190/2500. 0.8255 s / img. ETA=0:18:02
[32m[10/16 00:15:57 d2.evaluation.evaluator]: [0mInference done 1197/2500. 0.8255 s / img. ETA=0:17:56
[32m[10/16 00:16:03 d2.evaluation.evaluator]: [0mInference done 1204/2500. 0.8254 s / img. ETA=0:17:50
[32m[10/16 00:16:08 d2.evaluation.evaluator]: [0mInference done 1211/2500. 0.8253 s / img. ETA=0:17:44
[32m[10/16 00:16:14 d2.evaluation.evaluator]: [0mInference done 1218/2500. 0.8249 s / img. ETA=0:17:38
[32m[10/16 00:16:19 d2.evaluation.evaluator]: [0mInference done 1225/2500. 0.8244 s / img. ETA=0:17:32
[32m[10/16 00:16:24 d2.evaluation.evaluator]: [0mInference done 1231/2500. 0.8245 s / img. ETA=0:17:27
[32m[10/16 00:16:30 d2.evaluation.evaluator]: [0mInference done 1238/2500. 0.8243 s / img. ETA=0:17:21
[32m[10/16 00:16:35 d2.evaluation.evaluator]: [0mInference done 1245/2500. 0.8242 s / img. ETA=0:17:15
[32m[10/16 00:16:41 d2.evaluation.evaluator]: [0mInference done 1252/2500. 0.8241 s / img. ETA=0:17:09
[32m[10/16 00:16:46 d2.evaluation.evaluator]: [0mInference done 1259/2500. 0.8238 s / img. ETA=0:17:03
[32m[10/16 00:16:52 d2.evaluation.evaluator]: [0mInference done 1266/2500. 0.8237 s / img. ETA=0:16:57
[32m[10/16 00:16:57 d2.evaluation.evaluator]: [0mInference done 1273/2500. 0.8235 s / img. ETA=0:16:51
[32m[10/16 00:17:03 d2.evaluation.evaluator]: [0mInference done 1280/2500. 0.8234 s / img. ETA=0:16:45
[32m[10/16 00:17:08 d2.evaluation.evaluator]: [0mInference done 1287/2500. 0.8231 s / img. ETA=0:16:39
[32m[10/16 00:17:14 d2.evaluation.evaluator]: [0mInference done 1294/2500. 0.8228 s / img. ETA=0:16:33
[32m[10/16 00:17:19 d2.evaluation.evaluator]: [0mInference done 1301/2500. 0.8227 s / img. ETA=0:16:27
[32m[10/16 00:17:25 d2.evaluation.evaluator]: [0mInference done 1308/2500. 0.8224 s / img. ETA=0:16:21
[32m[10/16 00:17:30 d2.evaluation.evaluator]: [0mInference done 1315/2500. 0.8220 s / img. ETA=0:16:15
[32m[10/16 00:17:36 d2.evaluation.evaluator]: [0mInference done 1322/2500. 0.8219 s / img. ETA=0:16:09
[32m[10/16 00:17:41 d2.evaluation.evaluator]: [0mInference done 1329/2500. 0.8215 s / img. ETA=0:16:02
[32m[10/16 00:17:46 d2.evaluation.evaluator]: [0mInference done 1336/2500. 0.8212 s / img. ETA=0:15:56
[32m[10/16 00:17:52 d2.evaluation.evaluator]: [0mInference done 1343/2500. 0.8211 s / img. ETA=0:15:51
[32m[10/16 00:17:57 d2.evaluation.evaluator]: [0mInference done 1350/2500. 0.8209 s / img. ETA=0:15:45
[32m[10/16 00:18:03 d2.evaluation.evaluator]: [0mInference done 1357/2500. 0.8206 s / img. ETA=0:15:39
[32m[10/16 00:18:08 d2.evaluation.evaluator]: [0mInference done 1364/2500. 0.8204 s / img. ETA=0:15:32
[32m[10/16 00:18:14 d2.evaluation.evaluator]: [0mInference done 1371/2500. 0.8203 s / img. ETA=0:15:27
[32m[10/16 00:18:20 d2.evaluation.evaluator]: [0mInference done 1378/2500. 0.8203 s / img. ETA=0:15:21
[32m[10/16 00:18:25 d2.evaluation.evaluator]: [0mInference done 1385/2500. 0.8203 s / img. ETA=0:15:15
[32m[10/16 00:18:31 d2.evaluation.evaluator]: [0mInference done 1392/2500. 0.8203 s / img. ETA=0:15:09
[32m[10/16 00:18:36 d2.evaluation.evaluator]: [0mInference done 1399/2500. 0.8198 s / img. ETA=0:15:03
[32m[10/16 00:18:42 d2.evaluation.evaluator]: [0mInference done 1406/2500. 0.8196 s / img. ETA=0:14:57
[32m[10/16 00:18:47 d2.evaluation.evaluator]: [0mInference done 1413/2500. 0.8192 s / img. ETA=0:14:51
[32m[10/16 00:18:52 d2.evaluation.evaluator]: [0mInference done 1420/2500. 0.8189 s / img. ETA=0:14:45
[32m[10/16 00:18:58 d2.evaluation.evaluator]: [0mInference done 1427/2500. 0.8188 s / img. ETA=0:14:39
[32m[10/16 00:19:03 d2.evaluation.evaluator]: [0mInference done 1434/2500. 0.8187 s / img. ETA=0:14:33
[32m[10/16 00:19:09 d2.evaluation.evaluator]: [0mInference done 1441/2500. 0.8186 s / img. ETA=0:14:27
[32m[10/16 00:19:14 d2.evaluation.evaluator]: [0mInference done 1448/2500. 0.8185 s / img. ETA=0:14:21
[32m[10/16 00:19:20 d2.evaluation.evaluator]: [0mInference done 1455/2500. 0.8180 s / img. ETA=0:14:15
[32m[10/16 00:19:25 d2.evaluation.evaluator]: [0mInference done 1462/2500. 0.8179 s / img. ETA=0:14:09
[32m[10/16 00:19:30 d2.evaluation.evaluator]: [0mInference done 1469/2500. 0.8176 s / img. ETA=0:14:03
[32m[10/16 00:19:36 d2.evaluation.evaluator]: [0mInference done 1476/2500. 0.8174 s / img. ETA=0:13:57
[32m[10/16 00:19:41 d2.evaluation.evaluator]: [0mInference done 1483/2500. 0.8171 s / img. ETA=0:13:51
[32m[10/16 00:19:47 d2.evaluation.evaluator]: [0mInference done 1490/2500. 0.8170 s / img. ETA=0:13:46
[32m[10/16 00:19:52 d2.evaluation.evaluator]: [0mInference done 1497/2500. 0.8169 s / img. ETA=0:13:40
[32m[10/16 00:19:58 d2.evaluation.evaluator]: [0mInference done 1504/2500. 0.8167 s / img. ETA=0:13:34
[32m[10/16 00:20:03 d2.evaluation.evaluator]: [0mInference done 1511/2500. 0.8166 s / img. ETA=0:13:28
[32m[10/16 00:20:08 d2.evaluation.evaluator]: [0mInference done 1518/2500. 0.8162 s / img. ETA=0:13:22
[32m[10/16 00:20:14 d2.evaluation.evaluator]: [0mInference done 1525/2500. 0.8160 s / img. ETA=0:13:16
[32m[10/16 00:20:19 d2.evaluation.evaluator]: [0mInference done 1532/2500. 0.8157 s / img. ETA=0:13:10
[32m[10/16 00:20:24 d2.evaluation.evaluator]: [0mInference done 1538/2500. 0.8159 s / img. ETA=0:13:05
[32m[10/16 00:20:30 d2.evaluation.evaluator]: [0mInference done 1545/2500. 0.8158 s / img. ETA=0:12:59
[32m[10/16 00:20:35 d2.evaluation.evaluator]: [0mInference done 1552/2500. 0.8158 s / img. ETA=0:12:54
[32m[10/16 00:20:41 d2.evaluation.evaluator]: [0mInference done 1559/2500. 0.8155 s / img. ETA=0:12:48
[32m[10/16 00:20:46 d2.evaluation.evaluator]: [0mInference done 1566/2500. 0.8153 s / img. ETA=0:12:42
[32m[10/16 00:20:51 d2.evaluation.evaluator]: [0mInference done 1573/2500. 0.8151 s / img. ETA=0:12:36
[32m[10/16 00:20:57 d2.evaluation.evaluator]: [0mInference done 1580/2500. 0.8150 s / img. ETA=0:12:30
[32m[10/16 00:21:03 d2.evaluation.evaluator]: [0mInference done 1587/2500. 0.8149 s / img. ETA=0:12:24
[32m[10/16 00:21:08 d2.evaluation.evaluator]: [0mInference done 1594/2500. 0.8147 s / img. ETA=0:12:18
[32m[10/16 00:21:13 d2.evaluation.evaluator]: [0mInference done 1601/2500. 0.8145 s / img. ETA=0:12:13
[32m[10/16 00:21:19 d2.evaluation.evaluator]: [0mInference done 1608/2500. 0.8142 s / img. ETA=0:12:07
[32m[10/16 00:21:24 d2.evaluation.evaluator]: [0mInference done 1614/2500. 0.8143 s / img. ETA=0:12:02
[32m[10/16 00:21:29 d2.evaluation.evaluator]: [0mInference done 1621/2500. 0.8140 s / img. ETA=0:11:56
[32m[10/16 00:21:34 d2.evaluation.evaluator]: [0mInference done 1628/2500. 0.8138 s / img. ETA=0:11:50
[32m[10/16 00:21:40 d2.evaluation.evaluator]: [0mInference done 1635/2500. 0.8136 s / img. ETA=0:11:44
[32m[10/16 00:21:45 d2.evaluation.evaluator]: [0mInference done 1642/2500. 0.8135 s / img. ETA=0:11:38
[32m[10/16 00:21:51 d2.evaluation.evaluator]: [0mInference done 1649/2500. 0.8134 s / img. ETA=0:11:32
[32m[10/16 00:21:56 d2.evaluation.evaluator]: [0mInference done 1656/2500. 0.8132 s / img. ETA=0:11:27
[32m[10/16 00:22:02 d2.evaluation.evaluator]: [0mInference done 1663/2500. 0.8131 s / img. ETA=0:11:21
[32m[10/16 00:22:07 d2.evaluation.evaluator]: [0mInference done 1670/2500. 0.8129 s / img. ETA=0:11:15
[32m[10/16 00:22:13 d2.evaluation.evaluator]: [0mInference done 1677/2500. 0.8129 s / img. ETA=0:11:09
[32m[10/16 00:22:18 d2.evaluation.evaluator]: [0mInference done 1684/2500. 0.8129 s / img. ETA=0:11:04
[32m[10/16 00:22:24 d2.evaluation.evaluator]: [0mInference done 1691/2500. 0.8128 s / img. ETA=0:10:58
[32m[10/16 00:22:30 d2.evaluation.evaluator]: [0mInference done 1698/2500. 0.8128 s / img. ETA=0:10:52
[32m[10/16 00:22:35 d2.evaluation.evaluator]: [0mInference done 1705/2500. 0.8126 s / img. ETA=0:10:46
[32m[10/16 00:22:41 d2.evaluation.evaluator]: [0mInference done 1712/2500. 0.8126 s / img. ETA=0:10:41
[32m[10/16 00:22:46 d2.evaluation.evaluator]: [0mInference done 1719/2500. 0.8124 s / img. ETA=0:10:35
[32m[10/16 00:22:52 d2.evaluation.evaluator]: [0mInference done 1727/2500. 0.8118 s / img. ETA=0:10:28
[32m[10/16 00:22:57 d2.evaluation.evaluator]: [0mInference done 1735/2500. 0.8114 s / img. ETA=0:10:21
[32m[10/16 00:23:03 d2.evaluation.evaluator]: [0mInference done 1743/2500. 0.8110 s / img. ETA=0:10:14
[32m[10/16 00:23:08 d2.evaluation.evaluator]: [0mInference done 1750/2500. 0.8108 s / img. ETA=0:10:08
[32m[10/16 00:23:14 d2.evaluation.evaluator]: [0mInference done 1758/2500. 0.8103 s / img. ETA=0:10:01
[32m[10/16 00:23:20 d2.evaluation.evaluator]: [0mInference done 1766/2500. 0.8098 s / img. ETA=0:09:55
[32m[10/16 00:23:25 d2.evaluation.evaluator]: [0mInference done 1774/2500. 0.8092 s / img. ETA=0:09:48
[32m[10/16 00:23:30 d2.evaluation.evaluator]: [0mInference done 1782/2500. 0.8086 s / img. ETA=0:09:41
[32m[10/16 00:23:36 d2.evaluation.evaluator]: [0mInference done 1790/2500. 0.8079 s / img. ETA=0:09:34
[32m[10/16 00:23:41 d2.evaluation.evaluator]: [0mInference done 1798/2500. 0.8073 s / img. ETA=0:09:27
[32m[10/16 00:23:46 d2.evaluation.evaluator]: [0mInference done 1806/2500. 0.8066 s / img. ETA=0:09:20
[32m[10/16 00:23:52 d2.evaluation.evaluator]: [0mInference done 1814/2500. 0.8059 s / img. ETA=0:09:13
[32m[10/16 00:23:57 d2.evaluation.evaluator]: [0mInference done 1822/2500. 0.8052 s / img. ETA=0:09:06
[32m[10/16 00:24:02 d2.evaluation.evaluator]: [0mInference done 1830/2500. 0.8045 s / img. ETA=0:08:59
[32m[10/16 00:24:07 d2.evaluation.evaluator]: [0mInference done 1838/2500. 0.8038 s / img. ETA=0:08:52
[32m[10/16 00:24:12 d2.evaluation.evaluator]: [0mInference done 1846/2500. 0.8031 s / img. ETA=0:08:45
[32m[10/16 00:24:17 d2.evaluation.evaluator]: [0mInference done 1854/2500. 0.8023 s / img. ETA=0:08:38
[32m[10/16 00:24:22 d2.evaluation.evaluator]: [0mInference done 1862/2500. 0.8017 s / img. ETA=0:08:32
[32m[10/16 00:24:27 d2.evaluation.evaluator]: [0mInference done 1870/2500. 0.8009 s / img. ETA=0:08:25
[32m[10/16 00:24:32 d2.evaluation.evaluator]: [0mInference done 1878/2500. 0.8002 s / img. ETA=0:08:18
[32m[10/16 00:24:38 d2.evaluation.evaluator]: [0mInference done 1886/2500. 0.7995 s / img. ETA=0:08:11
[32m[10/16 00:24:43 d2.evaluation.evaluator]: [0mInference done 1894/2500. 0.7988 s / img. ETA=0:08:04
[32m[10/16 00:24:48 d2.evaluation.evaluator]: [0mInference done 1902/2500. 0.7981 s / img. ETA=0:07:57
[32m[10/16 00:24:53 d2.evaluation.evaluator]: [0mInference done 1911/2500. 0.7972 s / img. ETA=0:07:50
[32m[10/16 00:24:59 d2.evaluation.evaluator]: [0mInference done 1920/2500. 0.7964 s / img. ETA=0:07:42
[32m[10/16 00:25:04 d2.evaluation.evaluator]: [0mInference done 1928/2500. 0.7957 s / img. ETA=0:07:35
[32m[10/16 00:25:09 d2.evaluation.evaluator]: [0mInference done 1937/2500. 0.7949 s / img. ETA=0:07:28
[32m[10/16 00:25:15 d2.evaluation.evaluator]: [0mInference done 1946/2500. 0.7940 s / img. ETA=0:07:20
[32m[10/16 00:25:21 d2.evaluation.evaluator]: [0mInference done 1955/2500. 0.7932 s / img. ETA=0:07:12
[32m[10/16 00:25:26 d2.evaluation.evaluator]: [0mInference done 1964/2500. 0.7924 s / img. ETA=0:07:05
[32m[10/16 00:25:32 d2.evaluation.evaluator]: [0mInference done 1973/2500. 0.7916 s / img. ETA=0:06:57
[32m[10/16 00:25:37 d2.evaluation.evaluator]: [0mInference done 1982/2500. 0.7908 s / img. ETA=0:06:50
[32m[10/16 00:25:43 d2.evaluation.evaluator]: [0mInference done 1991/2500. 0.7900 s / img. ETA=0:06:42
[32m[10/16 00:25:48 d2.evaluation.evaluator]: [0mInference done 1999/2500. 0.7893 s / img. ETA=0:06:35
[32m[10/16 00:25:53 d2.evaluation.evaluator]: [0mInference done 2008/2500. 0.7885 s / img. ETA=0:06:28
[32m[10/16 00:25:59 d2.evaluation.evaluator]: [0mInference done 2017/2500. 0.7877 s / img. ETA=0:06:20
[32m[10/16 00:26:04 d2.evaluation.evaluator]: [0mInference done 2026/2500. 0.7870 s / img. ETA=0:06:13
[32m[10/16 00:26:10 d2.evaluation.evaluator]: [0mInference done 2035/2500. 0.7862 s / img. ETA=0:06:05
[32m[10/16 00:26:15 d2.evaluation.evaluator]: [0mInference done 2044/2500. 0.7854 s / img. ETA=0:05:58
[32m[10/16 00:26:21 d2.evaluation.evaluator]: [0mInference done 2053/2500. 0.7846 s / img. ETA=0:05:51
[32m[10/16 00:26:26 d2.evaluation.evaluator]: [0mInference done 2062/2500. 0.7839 s / img. ETA=0:05:43
[32m[10/16 00:26:32 d2.evaluation.evaluator]: [0mInference done 2071/2500. 0.7831 s / img. ETA=0:05:36
[32m[10/16 00:26:37 d2.evaluation.evaluator]: [0mInference done 2080/2500. 0.7823 s / img. ETA=0:05:28
[32m[10/16 00:26:43 d2.evaluation.evaluator]: [0mInference done 2089/2500. 0.7816 s / img. ETA=0:05:21
[32m[10/16 00:26:48 d2.evaluation.evaluator]: [0mInference done 2098/2500. 0.7809 s / img. ETA=0:05:14
[32m[10/16 00:26:54 d2.evaluation.evaluator]: [0mInference done 2107/2500. 0.7801 s / img. ETA=0:05:06
[32m[10/16 00:26:59 d2.evaluation.evaluator]: [0mInference done 2116/2500. 0.7794 s / img. ETA=0:04:59
[32m[10/16 00:27:05 d2.evaluation.evaluator]: [0mInference done 2125/2500. 0.7786 s / img. ETA=0:04:52
[32m[10/16 00:27:10 d2.evaluation.evaluator]: [0mInference done 2134/2500. 0.7779 s / img. ETA=0:04:45
[32m[10/16 00:27:15 d2.evaluation.evaluator]: [0mInference done 2143/2500. 0.7771 s / img. ETA=0:04:37
[32m[10/16 00:27:21 d2.evaluation.evaluator]: [0mInference done 2152/2500. 0.7764 s / img. ETA=0:04:30
[32m[10/16 00:27:26 d2.evaluation.evaluator]: [0mInference done 2161/2500. 0.7757 s / img. ETA=0:04:23
[32m[10/16 00:27:32 d2.evaluation.evaluator]: [0mInference done 2170/2500. 0.7750 s / img. ETA=0:04:16
[32m[10/16 00:27:37 d2.evaluation.evaluator]: [0mInference done 2179/2500. 0.7742 s / img. ETA=0:04:08
[32m[10/16 00:27:43 d2.evaluation.evaluator]: [0mInference done 2188/2500. 0.7735 s / img. ETA=0:04:01
[32m[10/16 00:27:48 d2.evaluation.evaluator]: [0mInference done 2197/2500. 0.7728 s / img. ETA=0:03:54
[32m[10/16 00:27:54 d2.evaluation.evaluator]: [0mInference done 2206/2500. 0.7722 s / img. ETA=0:03:47
[32m[10/16 00:27:59 d2.evaluation.evaluator]: [0mInference done 2215/2500. 0.7714 s / img. ETA=0:03:40
[32m[10/16 00:28:04 d2.evaluation.evaluator]: [0mInference done 2224/2500. 0.7707 s / img. ETA=0:03:32
[32m[10/16 00:28:10 d2.evaluation.evaluator]: [0mInference done 2233/2500. 0.7700 s / img. ETA=0:03:25
[32m[10/16 00:28:15 d2.evaluation.evaluator]: [0mInference done 2242/2500. 0.7694 s / img. ETA=0:03:18
[32m[10/16 00:28:21 d2.evaluation.evaluator]: [0mInference done 2251/2500. 0.7687 s / img. ETA=0:03:11
[32m[10/16 00:28:26 d2.evaluation.evaluator]: [0mInference done 2260/2500. 0.7680 s / img. ETA=0:03:04
[32m[10/16 00:28:31 d2.evaluation.evaluator]: [0mInference done 2269/2500. 0.7674 s / img. ETA=0:02:57
[32m[10/16 00:28:37 d2.evaluation.evaluator]: [0mInference done 2278/2500. 0.7667 s / img. ETA=0:02:50
[32m[10/16 00:28:42 d2.evaluation.evaluator]: [0mInference done 2287/2500. 0.7661 s / img. ETA=0:02:43
[32m[10/16 00:28:48 d2.evaluation.evaluator]: [0mInference done 2296/2500. 0.7654 s / img. ETA=0:02:36
[32m[10/16 00:28:53 d2.evaluation.evaluator]: [0mInference done 2305/2500. 0.7647 s / img. ETA=0:02:29
[32m[10/16 00:28:58 d2.evaluation.evaluator]: [0mInference done 2314/2500. 0.7641 s / img. ETA=0:02:22
[32m[10/16 00:29:04 d2.evaluation.evaluator]: [0mInference done 2323/2500. 0.7634 s / img. ETA=0:02:15
[32m[10/16 00:29:09 d2.evaluation.evaluator]: [0mInference done 2332/2500. 0.7628 s / img. ETA=0:02:08
[32m[10/16 00:29:15 d2.evaluation.evaluator]: [0mInference done 2341/2500. 0.7622 s / img. ETA=0:02:01
[32m[10/16 00:29:20 d2.evaluation.evaluator]: [0mInference done 2350/2500. 0.7616 s / img. ETA=0:01:54
[32m[10/16 00:29:25 d2.evaluation.evaluator]: [0mInference done 2359/2500. 0.7609 s / img. ETA=0:01:47
[32m[10/16 00:29:31 d2.evaluation.evaluator]: [0mInference done 2368/2500. 0.7603 s / img. ETA=0:01:40
[32m[10/16 00:29:36 d2.evaluation.evaluator]: [0mInference done 2377/2500. 0.7597 s / img. ETA=0:01:33
[32m[10/16 00:29:41 d2.evaluation.evaluator]: [0mInference done 2386/2500. 0.7591 s / img. ETA=0:01:26
[32m[10/16 00:29:47 d2.evaluation.evaluator]: [0mInference done 2395/2500. 0.7585 s / img. ETA=0:01:19
[32m[10/16 00:29:52 d2.evaluation.evaluator]: [0mInference done 2404/2500. 0.7578 s / img. ETA=0:01:12
[32m[10/16 00:29:58 d2.evaluation.evaluator]: [0mInference done 2413/2500. 0.7572 s / img. ETA=0:01:05
[32m[10/16 00:30:03 d2.evaluation.evaluator]: [0mInference done 2422/2500. 0.7566 s / img. ETA=0:00:59
[32m[10/16 00:30:08 d2.evaluation.evaluator]: [0mInference done 2431/2500. 0.7560 s / img. ETA=0:00:52
[32m[10/16 00:30:14 d2.evaluation.evaluator]: [0mInference done 2440/2500. 0.7555 s / img. ETA=0:00:45
[32m[10/16 00:30:19 d2.evaluation.evaluator]: [0mInference done 2449/2500. 0.7549 s / img. ETA=0:00:38
[32m[10/16 00:30:25 d2.evaluation.evaluator]: [0mInference done 2458/2500. 0.7543 s / img. ETA=0:00:31
[32m[10/16 00:30:30 d2.evaluation.evaluator]: [0mInference done 2467/2500. 0.7537 s / img. ETA=0:00:24
[32m[10/16 00:30:35 d2.evaluation.evaluator]: [0mInference done 2476/2500. 0.7532 s / img. ETA=0:00:18
[32m[10/16 00:30:41 d2.evaluation.evaluator]: [0mInference done 2485/2500. 0.7525 s / img. ETA=0:00:11
[32m[10/16 00:30:46 d2.evaluation.evaluator]: [0mInference done 2494/2500. 0.7520 s / img. ETA=0:00:04
[32m[10/16 00:30:50 d2.evaluation.evaluator]: [0mTotal inference time: 0:31:17.799511 (0.752625 s / img per device, on 2 devices)
[32m[10/16 00:30:50 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:31:15 (0.751595 s / img per device, on 2 devices)
[32m[10/16 00:30:50 fewx.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[10/16 00:30:50 fewx.evaluation.coco_evaluation]: [0mSaving results to ./output/fsod/finetune_dir/R_50_C4_1x/inference/coco_instances_results.json
[32m[10/16 00:30:50 fewx.evaluation.coco_evaluation]: [0mEvaluating predictions ...
Loading and preparing results...
DONE (t=0.05s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 4.60 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.57 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.029
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.056
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.029
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.008
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.051
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.048
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.067
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.067
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.010
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.061
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.116
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 2.934 | 5.555  | 2.858  | 0.778 | 3.240 | 5.121 |
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for VOC 20 categories =======> AP  : 11.74
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for VOC 20 categories =======> AP50: 22.22
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for VOC 20 categories =======> AP75: 11.43
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for VOC 20 categories =======> APs : 3.11
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for VOC 20 categories =======> APm : 12.96
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for VOC 20 categories =======> APl : 20.48
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for Non VOC 60 categories =======> AP  : 0.00
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for Non VOC 60 categories =======> AP50: 0.00
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for Non VOC 60 categories =======> AP75: 0.00
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for Non VOC 60 categories =======> APs : 0.00
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for Non VOC 60 categories =======> APm : 0.00
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mEvaluation results for Non VOC 60 categories =======> APl : 0.00
[32m[10/16 00:30:56 fewx.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category      | AP     | category     | AP     | category       | AP     |
|:--------------|:-------|:-------------|:-------|:---------------|:-------|
| person        | 11.037 | bicycle      | 4.895  | car            | 12.431 |
| motorcycle    | 10.409 | airplane     | 23.316 | bus            | 20.512 |
| train         | 14.022 | truck        | 0.000  | boat           | 1.470  |
| traffic light | 0.000  | fire hydrant | 0.000  | stop sign      | 0.000  |
| parking meter | 0.000  | bench        | 0.000  | bird           | 8.047  |
| cat           | 25.214 | dog          | 17.326 | horse          | 12.902 |
| sheep         | 5.761  | cow          | 6.971  | elephant       | 0.000  |
| bear          | 0.000  | zebra        | 0.000  | giraffe        | 0.000  |
| backpack      | 0.000  | umbrella     | 0.000  | handbag        | 0.000  |
| tie           | 0.000  | suitcase     | 0.000  | frisbee        | 0.000  |
| skis          | 0.000  | snowboard    | 0.000  | sports ball    | 0.000  |
| kite          | 0.000  | baseball bat | 0.000  | baseball glove | 0.000  |
| skateboard    | 0.000  | surfboard    | 0.000  | tennis racket  | 0.000  |
| bottle        | 7.675  | wine glass   | 0.000  | cup            | 0.000  |
| fork          | 0.000  | knife        | 0.000  | spoon          | 0.000  |
| bowl          | 0.000  | banana       | 0.000  | apple          | 0.000  |
| sandwich      | 0.000  | orange       | 0.000  | broccoli       | 0.000  |
| carrot        | 0.000  | hot dog      | 0.000  | pizza          | 0.000  |
| donut         | 0.000  | cake         | 0.000  | chair          | 2.163  |
| couch         | 11.604 | potted plant | 4.135  | bed            | 0.000  |
| dining table  | 9.233  | toilet       | 0.000  | tv             | 25.592 |
| laptop        | 0.000  | mouse        | 0.000  | remote         | 0.000  |
| keyboard      | 0.000  | cell phone   | 0.000  | microwave      | 0.000  |
| oven          | 0.000  | toaster      | 0.000  | sink           | 0.000  |
| refrigerator  | 0.000  | book         | 0.000  | clock          | 0.000  |
| vase          | 0.000  | scissors     | 0.000  | teddy bear     | 0.000  |
| hair drier    | 0.000  | toothbrush   | 0.000  |                |        |
[32m[10/16 00:30:56 d2.engine.defaults]: [0mEvaluation results for coco_2017_val in csv format:
[32m[10/16 00:30:56 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[10/16 00:30:56 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[10/16 00:30:56 d2.evaluation.testing]: [0mcopypaste: 2.9340,5.5548,2.8576,0.7775,3.2403,5.1206
